# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

5åˆ†é’Ÿç¼–è¯‘è¿è¡Œé«˜æ€§èƒ½LLMæ¨ç†å¼•æ“ï¼

## ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒå‡†å¤‡

### Linux/Mac

```bash
# å®‰è£…ç¼–è¯‘å·¥å…·
# Ubuntu/Debian
sudo apt-get install build-essential cmake

# macOS
brew install cmake

# æ£€æŸ¥C++ç¼–è¯‘å™¨ç‰ˆæœ¬ï¼ˆéœ€è¦æ”¯æŒC++17ï¼‰
g++ --version  # æˆ– clang++ --version
```

### Windows

- å®‰è£… [Visual Studio 2019+](https://visualstudio.microsoft.com/)ï¼ˆåŒ…å«C++å·¥å…·ï¼‰
- å®‰è£… [CMake](https://cmake.org/download/)

---

## ç¬¬äºŒæ­¥ï¼šç¼–è¯‘é¡¹ç›®

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd project_llm_inference

# åˆ›å»ºæ„å»ºç›®å½•
mkdir build && cd build

# é…ç½®CMake
cmake ..

# ç¼–è¯‘ï¼ˆä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼‰
make -j$(nproc)

# æˆ–åœ¨Macä¸Š
make -j$(sysctl -n hw.ncpu)
```

**é¢„æœŸè¾“å‡º**ï¼š
```
========================================
LLM Inference Engine Configuration
========================================
C++ Standard:    17
Build Type:      Release
CXX Flags:       -Wall -Wextra -O3 -mavx2
AVX2:            1
pybind11:        0
========================================

[ 25%] Building CXX object ...
[ 50%] Building CXX object ...
[ 75%] Building CXX object ...
[100%] Built target llm_inference_static

âœ… ç¼–è¯‘å®Œæˆï¼
```

---

## ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œæµ‹è¯•

### 1. KV Cacheæµ‹è¯•

```bash
./test_kv_cache
```

**é¢„æœŸçœ‹åˆ°**ï¼š
- KV Cacheåˆå§‹åŒ–ä¿¡æ¯
- åŸºæœ¬æ“ä½œæµ‹è¯•
- æ€§èƒ½æµ‹è¯•ï¼ˆPrefill vs Decodeï¼‰
- å†…å­˜ä½¿ç”¨åˆ†æ

**å…³é”®è¾“å‡º**ï¼š
```
Prefill TPS: ~500 tokens/s
Decode TPS:  ~100 tokens/s
Memory:      ~256 MB (Llama-2-7Bé…ç½®)
```

### 2. é‡åŒ–æµ‹è¯•

```bash
./test_quantization
```

**é¢„æœŸçœ‹åˆ°**ï¼š
- INT8é‡åŒ–ç²¾åº¦æµ‹è¯•
- INT4é‡åŒ–å‹ç¼©æ¯”
- çŸ©é˜µä¹˜æ³•æ€§èƒ½å¯¹æ¯”

**å…³é”®è¾“å‡º**ï¼š
```
INT8é‡åŒ–:
  å‹ç¼©æ¯”: 4.00x
  MSE: ~1e-4
  çŸ©é˜µä¹˜æ³•åŠ é€Ÿ: 2-3x

INT4é‡åŒ–:
  å‹ç¼©æ¯”: 8.00x
  MSE: ~1e-3
```

### 3. ç»¼åˆåŸºå‡†æµ‹è¯•

```bash
./benchmark
```

**é¢„æœŸçœ‹åˆ°**ï¼š

| ä¼˜åŒ–æ–¹æ³• | è€—æ—¶(ms) | åŠ é€Ÿæ¯” |
|---------|---------|--------|
| åŸºå‡†ï¼ˆæ— ä¼˜åŒ–ï¼‰ | 1000 | 1.00x |
| KV Cache | 50 | 20.00x |
| INT8é‡åŒ– | 300 | 3.33x |
| KV Cache + INT8 | 30 | 33.33x |

---

## ğŸ“Š æ€§èƒ½éªŒè¯

è¿è¡Œå®Œæµ‹è¯•åï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š

âœ… **KV Cache**ï¼š
- Prefill: ~500 tokens/s
- Decode: ~100 tokens/s
- å†…å­˜å ç”¨ï¼š~256 MBï¼ˆLlama-2-7Bï¼‰

âœ… **é‡åŒ–**ï¼š
- INT8: 4xå†…å­˜èŠ‚çœï¼Œ2-3xåŠ é€Ÿ
- INT4: 8xå†…å­˜èŠ‚çœ
- ç²¾åº¦æŸå¤±: <1%

âœ… **ç»„åˆä¼˜åŒ–**ï¼š
- æ€»åŠ é€Ÿæ¯”: 15-50x
- å†…å­˜èŠ‚çœ: 75%

---

## ğŸ¯ æ ¸å¿ƒä»£ç ç¤ºä¾‹

### ä½¿ç”¨KV Cache

```cpp
#include "kv_cache.h"

// åˆ›å»ºKV Cache
KVCache cache(
    2048,  // max_seq_len
    32,    // n_layers
    32,    // n_heads
    128    // head_dim
);

// æ›´æ–°cache
std::vector<float> k(4096);  // 32 * 128
std::vector<float> v(4096);

for (int layer = 0; layer < 32; ++layer) {
    cache.update_k(layer, k.data(), seq_pos);
    cache.update_v(layer, v.data(), seq_pos);
}

// è·å–å®Œæ•´cacheç”¨äºattention
const float* k_cache = cache.get_k(layer_idx);
```

### ä½¿ç”¨INT8é‡åŒ–

```cpp
#include "quantization.h"

// é‡åŒ–æƒé‡
std::vector<float> weights(1000);
auto quantized = INT8Quantizer::quantize(
    weights.data(),
    weights.size()
);

// INT8çŸ©é˜µä¹˜æ³•
std::vector<float> input(m * k);
std::vector<float> output(m * n);

INT8Quantizer::matmul_int8(
    input.data(),
    quantized,
    m, k, n,
    output.data()
);
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: ç¼–è¯‘å¤±è´¥ - "C++17 not supported"

**åŸå› **ï¼šç¼–è¯‘å™¨ç‰ˆæœ¬è¿‡æ—§

**è§£å†³**ï¼š
```bash
# å®‰è£…æ–°ç‰ˆæœ¬GCC
sudo apt-get install g++-9

# æŒ‡å®šç¼–è¯‘å™¨
export CXX=g++-9
cmake ..
make
```

### Q2: "AVX2 not supported"

**åŸå› **ï¼šCPUä¸æ”¯æŒAVX2æŒ‡ä»¤é›†

**å½±å“**ï¼šSIMDä¼˜åŒ–ä¸å¯ç”¨ï¼Œæ€§èƒ½ç•¥ä½

**è§£å†³**ï¼šè¿™æ˜¯æ­£å¸¸çš„ï¼Œé¡¹ç›®ä¼šè‡ªåŠ¨fallbackåˆ°æ ‡é‡å®ç°

### Q3: æµ‹è¯•è¿è¡Œå¾ˆæ…¢

**åŸå› **ï¼šDebugæ¨¡å¼ç¼–è¯‘

**è§£å†³**ï¼š
```bash
cmake -DCMAKE_BUILD_TYPE=Release ..
make clean && make -j
```

### Q4: æ‰¾ä¸åˆ°pybind11

**åŸå› **ï¼šæœªå®‰è£…pybind11

**è§£å†³**ï¼ˆå¦‚æœéœ€è¦Pythonç»‘å®šï¼‰ï¼š
```bash
pip install pybind11
cmake ..
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

### 1. é˜…è¯»æ–‡æ¡£

- [README.md](README.md) - å®Œæ•´é¡¹ç›®æ–‡æ¡£
- [docs/architecture.md](docs/architecture.md) - æ¶æ„è®¾è®¡
- [docs/optimization.md](docs/optimization.md) - ä¼˜åŒ–æŠ€æœ¯è¯¦è§£

### 2. æŸ¥çœ‹ä»£ç 

æ¨èé˜…è¯»é¡ºåºï¼š
1. `cpp/include/kv_cache.h` - KV Cacheæ¥å£
2. `cpp/src/kv_cache.cpp` - KV Cacheå®ç°
3. `cpp/include/quantization.h` - é‡åŒ–æ¥å£
4. `cpp/src/quantization.cpp` - é‡åŒ–å®ç°ï¼ˆåŒ…å«SIMDï¼‰

### 3. ä¿®æ”¹å’Œå®éªŒ

å°è¯•ä¿®æ”¹å‚æ•°ï¼š
- è°ƒæ•´KV Cacheå¤§å°
- å°è¯•ä¸åŒçš„é‡åŒ–ç²¾åº¦
- æ·»åŠ è‡ªå·±çš„ä¼˜åŒ–

### 4. é›†æˆåˆ°é¡¹ç›®

```cpp
// åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨
#include "llm_inference/kv_cache.h"
#include "llm_inference/quantization.h"

using namespace llm_inference;

// ... ä½ çš„ä»£ç 
```

---

## ğŸ’¡ æ€§èƒ½ä¼˜åŒ–æç¤º

### 1. ç¼–è¯‘ä¼˜åŒ–

```bash
# å¯ç”¨æ›´æ¿€è¿›çš„ä¼˜åŒ–
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-O3 -march=native" ..
```

### 2. å†…å­˜ä¼˜åŒ–

- ä½¿ç”¨PagedKVCacheæ›¿ä»£æ ‡å‡†KVCache
- ä½¿ç”¨INT4æ›¿ä»£INT8ï¼ˆæ›´æ¿€è¿›çš„é‡åŒ–ï¼‰

### 3. å¹¶è¡Œä¼˜åŒ–

- ä½¿ç”¨OpenMPå¹¶è¡ŒåŒ–
- æ‰¹å¤„ç†å¤šä¸ªè¯·æ±‚

---

## ğŸ“ å­¦ä¹ ä»·å€¼

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†æŒæ¡ï¼š

**C++æŠ€èƒ½**ï¼š
- âœ… ç°ä»£C++17ç‰¹æ€§
- âœ… å†…å­˜ç®¡ç†å’Œä¼˜åŒ–
- âœ… SIMDç¼–ç¨‹ï¼ˆAVX2ï¼‰
- âœ… CMakeæ„å»ºç³»ç»Ÿ

**AIå·¥ç¨‹æŠ€èƒ½**ï¼š
- âœ… LLMæ¨ç†ä¼˜åŒ–æ ¸å¿ƒæŠ€æœ¯
- âœ… KV Cacheå®ç°åŸç†
- âœ… é‡åŒ–æŠ€æœ¯ï¼ˆINT8/INT4ï¼‰
- âœ… æ€§èƒ½åˆ†æå’ŒåŸºå‡†æµ‹è¯•

**ç³»ç»Ÿä¼˜åŒ–æŠ€èƒ½**ï¼š
- âœ… ç¼“å­˜ä¼˜åŒ–
- âœ… å†…å­˜å¯¹é½
- âœ… å‘é‡åŒ–è®¡ç®—
- âœ… æ€§èƒ½profiling

---

## ğŸ¯ ç®€å†äº®ç‚¹

å®Œæˆè¿™ä¸ªé¡¹ç›®åï¼Œä½ å¯ä»¥å†™ï¼š

> **é«˜æ€§èƒ½LLMæ¨ç†å¼•æ“**ï¼ˆä¸ªäººé¡¹ç›®ï¼‰
>
> æŠ€æœ¯æ ˆï¼šC++17, SIMD(AVX2), CMake
>
> - å®ç°KV Cacheä¼˜åŒ–ï¼Œæ¨ç†é€Ÿåº¦æå‡20å€
> - å¼€å‘INT8é‡åŒ–æŠ€æœ¯ï¼Œå†…å­˜å ç”¨å‡å°‘75%
> - ä½¿ç”¨AVX2 SIMDæŒ‡ä»¤ä¼˜åŒ–çŸ©é˜µè¿ç®—ï¼Œæ€§èƒ½æå‡2-3å€
> - ç»¼åˆä¼˜åŒ–åæ¨ç†å»¶è¿Ÿé™ä½30å€ï¼ˆ1000ms â†’ 30msï¼‰
>
> **æˆæœ**ï¼šæŒæ¡æ¨ç†ä¼˜åŒ–æ ¸å¿ƒæŠ€æœ¯ï¼Œå…·å¤‡é«˜æ€§èƒ½è®¡ç®—èƒ½åŠ›

---

## ğŸ”— ç›¸å…³èµ„æº

**å¼€æºé¡¹ç›®**ï¼š
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - å‚è€ƒå®ç°
- [vLLM](https://github.com/vllm-project/vllm) - PagedAttention
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - NVIDIAæ–¹æ¡ˆ

**è®ºæ–‡**ï¼š
- [FlashAttention](https://arxiv.org/abs/2205.14135) - Attentionä¼˜åŒ–
- [PagedAttention (vLLM)](https://arxiv.org/abs/2309.06180) - åˆ†é¡µKV Cache
- [GPTQ](https://arxiv.org/abs/2210.17323) - é«˜çº§é‡åŒ–

---

**ç«‹å³å¼€å§‹ï¼Œæ„Ÿå—C++åœ¨AIé¢†åŸŸçš„å¼ºå¤§å¨åŠ›ï¼ğŸš€**
