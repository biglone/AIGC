"""
ç¬¬äºŒä¸ªå®è·µï¼šç†è§£ä¸ºä»€ä¹ˆéœ€è¦KV Cacheä¼˜åŒ–

è¿™ä¸ªè„šæœ¬æ¨¡æ‹Ÿï¼š
1. æ²¡æœ‰KV Cacheæ—¶çš„é‡å¤è®¡ç®—
2. æœ‰KV Cacheæ—¶çš„ä¼˜åŒ–æ•ˆæœ
3. ä¸ºä»€ä¹ˆèƒ½åŠ é€Ÿ20å€

ä¸éœ€è¦API keyï¼Œçº¯æœ¬åœ°æ¼”ç¤º
"""

import time
import numpy as np


def simulate_attention_without_cache(seq_len):
    """æ¨¡æ‹Ÿæ²¡æœ‰KV Cacheçš„æ³¨æ„åŠ›è®¡ç®—"""
    print(f"\n{'='*60}")
    print(f"æ¨¡æ‹Ÿï¼šç”Ÿæˆ {seq_len} ä¸ªè¯ï¼ˆæ²¡æœ‰KV Cacheï¼‰")
    print(f"{'='*60}")

    total_ops = 0
    d = 64  # ç®€åŒ–çš„ç»´åº¦

    print("\næ¯ä¸€æ­¥çš„è®¡ç®—é‡ï¼š")
    for i in range(1, seq_len + 1):
        # æ¯æ¬¡éƒ½è¦é‡æ–°è®¡ç®—æ‰€æœ‰ä¹‹å‰çš„è¯
        ops = i * i * d  # O(n^2 * d)
        total_ops += ops
        if i <= 5 or i % 10 == 0 or i == seq_len:
            print(f"  ç”Ÿæˆç¬¬ {i:2d} ä¸ªè¯ï¼šéœ€è¦è®¡ç®— {i} x {i} = {i*i:4d} æ¬¡æ³¨æ„åŠ› "
                  f"â†’ {ops:8d} æ¬¡è¿ç®—")

    print(f"\næ€»è®¡ç®—é‡ï¼š{total_ops:,} æ¬¡è¿ç®—")
    return total_ops


def simulate_attention_with_cache(seq_len):
    """æ¨¡æ‹Ÿæœ‰KV Cacheçš„æ³¨æ„åŠ›è®¡ç®—"""
    print(f"\n{'='*60}")
    print(f"æ¨¡æ‹Ÿï¼šç”Ÿæˆ {seq_len} ä¸ªè¯ï¼ˆæœ‰KV Cacheï¼‰")
    print(f"{'='*60}")

    total_ops = 0
    d = 64

    print("\næ¯ä¸€æ­¥çš„è®¡ç®—é‡ï¼š")
    for i in range(1, seq_len + 1):
        # åªéœ€è¦è®¡ç®—æ–°è¯ä¸ä¹‹å‰æ‰€æœ‰è¯çš„æ³¨æ„åŠ›
        ops = i * d  # O(n * d)
        total_ops += ops
        if i <= 5 or i % 10 == 0 or i == seq_len:
            print(f"  ç”Ÿæˆç¬¬ {i:2d} ä¸ªè¯ï¼šåªéœ€è®¡ç®— {i} x 1 = {i:4d} æ¬¡æ³¨æ„åŠ› "
                  f"â†’ {ops:8d} æ¬¡è¿ç®—")

    print(f"\næ€»è®¡ç®—é‡ï¼š{total_ops:,} æ¬¡è¿ç®—")
    return total_ops


def real_benchmark():
    """å®é™…çš„æ€§èƒ½å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print(f"\n{'='*60}")
    print("å®é™…æ€§èƒ½æµ‹è¯•ï¼šæ¨¡æ‹ŸçŸ©é˜µè¿ç®—")
    print(f"{'='*60}")

    seq_len = 100
    d_model = 512

    # æ¨¡æ‹Ÿæ²¡æœ‰cacheçš„æƒ…å†µ
    print("\næµ‹è¯•1ï¼šæ²¡æœ‰KV Cache")
    start = time.time()
    total_time_no_cache = 0
    for i in range(1, seq_len + 1):
        # æ¯æ¬¡éƒ½é‡æ–°è®¡ç®—
        Q = np.random.randn(i, d_model)
        K = np.random.randn(i, d_model)
        V = np.random.randn(i, d_model)

        step_start = time.time()
        scores = Q @ K.T  # (i, i)
        attention = np.exp(scores) / np.exp(scores).sum(axis=1, keepdims=True)
        output = attention @ V
        step_time = time.time() - step_start
        total_time_no_cache += step_time

    time_no_cache = time.time() - start

    # æ¨¡æ‹Ÿæœ‰cacheçš„æƒ…å†µ
    print("\næµ‹è¯•2ï¼šæœ‰KV Cache")
    start = time.time()
    total_time_with_cache = 0

    # é¢„å…ˆåˆ†é…cache
    K_cache = np.zeros((seq_len, d_model))
    V_cache = np.zeros((seq_len, d_model))

    for i in range(1, seq_len + 1):
        # åªè®¡ç®—æ–°è¯
        Q_new = np.random.randn(1, d_model)
        K_new = np.random.randn(1, d_model)
        V_new = np.random.randn(1, d_model)

        step_start = time.time()
        # æ›´æ–°cache
        K_cache[i-1] = K_new
        V_cache[i-1] = V_new

        # åªéœ€è¦æ–°Qä¸æ‰€æœ‰Kçš„æ³¨æ„åŠ›
        scores = Q_new @ K_cache[:i].T  # (1, i)
        attention = np.exp(scores) / np.exp(scores).sum()
        output = attention @ V_cache[:i]
        step_time = time.time() - step_start
        total_time_with_cache += step_time

    time_with_cache = time.time() - start

    print(f"\nç»“æœå¯¹æ¯”ï¼š")
    print(f"  æ²¡æœ‰KV Cache: {time_no_cache:.3f} ç§’")
    print(f"  æœ‰KV Cache:   {time_with_cache:.3f} ç§’")
    print(f"  åŠ é€Ÿæ¯”:       {time_no_cache/time_with_cache:.1f}x")

    return time_no_cache, time_with_cache


def visualize_memory_usage():
    """å¯è§†åŒ–å†…å­˜ä½¿ç”¨"""
    print(f"\n{'='*60}")
    print("KV Cacheçš„å†…å­˜ä½¿ç”¨åˆ†æ")
    print(f"{'='*60}")

    # Llama-2-7Bçš„å‚æ•°
    n_layers = 32
    n_heads = 32
    d_head = 128
    batch_size = 1
    seq_len = 2048

    # æ¯ä¸ªtokençš„KV cacheå¤§å°
    kv_size_per_token = n_layers * 2 * n_heads * d_head * 2  # 2 for K and V, 2 bytes for FP16

    print(f"\næ¨¡å‹é…ç½®ï¼šLlama-2-7B")
    print(f"  - å±‚æ•°: {n_layers}")
    print(f"  - æ³¨æ„åŠ›å¤´æ•°: {n_heads}")
    print(f"  - æ¯ä¸ªå¤´çš„ç»´åº¦: {d_head}")
    print(f"  - åºåˆ—é•¿åº¦: {seq_len}")

    print(f"\nKV Cacheå†…å­˜å ç”¨ï¼š")
    print(f"  - æ¯ä¸ªtoken: {kv_size_per_token / 1024:.2f} KB")
    print(f"  - {seq_len}ä¸ªtoken: {kv_size_per_token * seq_len / 1024 / 1024:.2f} MB")

    print(f"\nğŸ’¡ è§‚å¯Ÿï¼š")
    print(f"   - KV Cacheç”¨å†…å­˜æ¢æ—¶é—´")
    print(f"   - åºåˆ—è¶Šé•¿ï¼Œå†…å­˜å ç”¨è¶Šå¤§")
    print(f"   - è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé•¿æ–‡æœ¬å¯¹è¯å¾ˆè´µï¼")


def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print(f"\n{'='*60}")
    print("äº¤äº’å¼æ¼”ç¤ºï¼šä½“éªŒè®¡ç®—é‡å·®å¼‚")
    print(f"{'='*60}")

    while True:
        try:
            seq_len = input("\nè¯·è¾“å…¥è¦ç”Ÿæˆçš„è¯æ•°ï¼ˆå»ºè®®10-100ï¼Œè¾“å…¥0é€€å‡ºï¼‰: ")
            seq_len = int(seq_len)

            if seq_len == 0:
                break

            if seq_len < 1 or seq_len > 1000:
                print("è¯·è¾“å…¥1-1000ä¹‹é—´çš„æ•°å­—")
                continue

            # è®¡ç®—ä¸¤ç§æ–¹å¼çš„è®¡ç®—é‡
            ops_no_cache = simulate_attention_without_cache(seq_len)
            ops_with_cache = simulate_attention_with_cache(seq_len)

            # å¯¹æ¯”
            print(f"\n{'='*60}")
            print("ğŸ“Š å¯¹æ¯”ç»“æœ")
            print(f"{'='*60}")
            print(f"æ²¡æœ‰KV Cache: {ops_no_cache:,} æ¬¡è¿ç®—")
            print(f"æœ‰KV Cache:   {ops_with_cache:,} æ¬¡è¿ç®—")
            print(f"åŠ é€Ÿæ¯”:       {ops_no_cache/ops_with_cache:.1f}x")
            print(f"èŠ‚çœè®¡ç®—:     {(1 - ops_with_cache/ops_no_cache)*100:.1f}%")

        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            break


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ“ ç†è§£KV Cacheä¼˜åŒ– ğŸ“".center(60))

    print("\nè¿™ä¸ªæ•™ç¨‹å°†å¸®åŠ©æ‚¨ç†è§£ï¼š")
    print("1. ä¸ºä»€ä¹ˆè‡ªå›å½’ç”Ÿæˆå¾ˆæ…¢")
    print("2. KV Cacheå¦‚ä½•ä¼˜åŒ–")
    print("3. ä¸ºä»€ä¹ˆèƒ½åŠ é€Ÿ20å€")
    print("4. å†…å­˜æ¢æ—¶é—´çš„æƒè¡¡\n")

    try:
        # æ¼”ç¤º1ï¼šç†è®ºåˆ†æ
        print("\n" + "ç¬¬1éƒ¨åˆ†ï¼šç†è®ºåˆ†æ".center(60, "-"))
        ops_no_cache = simulate_attention_without_cache(20)
        ops_with_cache = simulate_attention_with_cache(20)

        print(f"\nğŸ’¡ æ ¸å¿ƒæ´å¯Ÿï¼š")
        print(f"   æ²¡æœ‰cache: è®¡ç®—é‡ = 1+4+9+16+...+nÂ² = O(nÂ³)")
        print(f"   æœ‰cache:   è®¡ç®—é‡ = 1+2+3+4+...+n  = O(nÂ²)")
        print(f"   åŠ é€Ÿæ¯”: {ops_no_cache/ops_with_cache:.1f}x")

        input("\næŒ‰å›è½¦ç»§ç»­...")

        # æ¼”ç¤º2ï¼šå®é™…æ€§èƒ½
        print("\n" + "ç¬¬2éƒ¨åˆ†ï¼šå®é™…æ€§èƒ½æµ‹è¯•".center(60, "-"))
        real_benchmark()

        input("\næŒ‰å›è½¦ç»§ç»­...")

        # æ¼”ç¤º3ï¼šå†…å­˜åˆ†æ
        print("\n" + "ç¬¬3éƒ¨åˆ†ï¼šå†…å­˜ä½¿ç”¨åˆ†æ".center(60, "-"))
        visualize_memory_usage()

        input("\næŒ‰å›è½¦ç»§ç»­...")

        # æ¼”ç¤º4ï¼šäº¤äº’å¼
        print("\n" + "ç¬¬4éƒ¨åˆ†ï¼šäº¤äº’å¼ä½“éªŒ".center(60, "-"))
        interactive_demo()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ­å–œï¼æ‚¨å·²ç»ç†è§£äº†KV Cacheä¼˜åŒ–")
        print("=" * 60)
        print("\næ‚¨ç°åœ¨çŸ¥é“äº†ï¼š")
        print("âœ… ä¸ºä»€ä¹ˆè‡ªå›å½’ç”Ÿæˆéœ€è¦ä¼˜åŒ–")
        print("âœ… KV Cacheå¦‚ä½•é¿å…é‡å¤è®¡ç®—")
        print("âœ… ä¸ºä»€ä¹ˆèƒ½åŠ é€Ÿ20å€")
        print("âœ… å†…å­˜å’Œé€Ÿåº¦çš„æƒè¡¡")
        print("\nä¸‹ä¸€æ­¥ï¼šæŸ¥çœ‹ llm-inference-engine é¡¹ç›®çš„å®é™…C++å®ç°")

    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²é€€å‡º")


if __name__ == "__main__":
    main()
